<!doctype html>
<html lang="en">

<head>
  <!-- Required meta tags -->
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- Bootstrap CSS -->
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.0/dist/css/bootstrap.min.css" rel="stylesheet"
    integrity="sha384-wEmeIV1mKuiNpC+IOBjI7aAzPcEZeedi5yW5f2yOq55WWLwNGmvvx4Um1vskeMj0" crossorigin="anonymous">
  <link rel="stylesheet" href="assets/css/style.css">
  <title>Deciphering Big Data</title>
  <style>
    body {
      background-color: #000; /* Black background */
      color: #fff; /* White text */
    }

    .sidebar {
      height: 100%;
      width: 250px;
      position: fixed;
      top: 0;
      left: 0;
      background-color: #262626;
      padding-top: 20px;
    }

    .sidebar a {
      padding: 10px 15px;
      text-decoration: none;
      font-size: 18px;
      color: #fff;
      display: block;
    }

    .sidebar a:hover {
      background-color: #575757;
    }

    .content {
      margin-left: 270px;
      padding: 20px;
    }

    .unit {
      background-color: #fff; /* White background for units */
      color: #000; /* Black text for units */
      margin-bottom: 20px;
      padding: 20px;
      border-radius: 10px;
      box-shadow: 0 0 10px rgba(0, 0, 0, 0.5);
    }

    .btn-custom {
      margin-right: 10px;
    }
  </style>
</head>

<body>
  <div class="sidebar">
    <a href="#unit1">Unit 1</a>
    <a href="#unit2">Unit 2</a>
    <a href="#unit3">Unit 3</a>
    <a href="#unit4">Unit 4</a>
    <a href="#unit5">Unit 5</a>
    <a href="#unit6">Unit 6</a>
    <a href="#unit7">Unit 7</a>
    <a href="#unit8">Unit 8</a>
    <a href="#unit9">Unit 9</a>
    <a href="#unit10">Unit 10</a>
    <a href="#unit11">Unit 11</a>
    <a href="#unit12">Unit 12</a>
  </div>

  <div class="content">
    <h1 class="mt-5">Deciphering Big Data</h1>
    <div class="unit" id="unit1">
      <h1>Unit 1</h1>
     <h1>Introduction to Big Data Technologies and Data Management</h1>

          <h1>Summary of Learning Outcomes</h1>

<p>In Unit 1 of the module "Introduction to Big Data Technologies and Data Management," the learning outcomes and skills gained are essential for understanding and managing big data effectively. This unit provides a foundational overview of the characteristics, methodologies, and tools associated with big data, along with critical evaluations of data management strategies and security requirements.</p>

<h2>Key Learning Outcomes</h2>

<ol>
    <li>
        <span class="section-title">Understanding Big Data Characteristics and the 4Vs:</span>
        <ul>
            <li><strong>Volume:</strong> The scale of data generated.</li>
            <li><strong>Velocity:</strong> The speed at which data is generated and processed.</li>
            <li><strong>Variety:</strong> The different types of data (structured, semi-structured, unstructured).</li>
            <li><strong>Veracity:</strong> The uncertainty of data quality.</li>
        </ul>
    </li>
    <li>
        <span class="section-title">Exponential Growth and Complexity of Data:</span>
        <ul>
            <li>Awareness of how data is growing exponentially and the complexities associated with its management.</li>
        </ul>
    </li>
    <li>
        <span class="section-title">Data Management Tools and Strategies:</span>
        <ul>
            <li>Evaluation of various methodologies, tools, techniques, and strategies used for managing big data.</li>
        </ul>
    </li>
    <li>
        <span class="section-title">Data Security Requirements:</span>
        <ul>
            <li>Understanding the importance of data security and the requirements necessary to protect data.</li>
        </ul>
    </li>
    <li>
        <span class="section-title">Skill Requirements for Data Management Systems:</span>
        <ul>
            <li>Identifying the necessary skills for developing and maintaining a data management system.</li>
        </ul>
    </li>
</ol>


<h1>Reading and Study Hours</h1>

<div class="section">
    <div class="section-title">Primary Reading:</div>
    <ul>
        <li>
            <span class="book-title">Sarkar, T. & Roychowdhury, S. (2019) Data Wrangling with Python. 1st ed. Packt.</span>
            <ul>
                <li>Chapter 1: This chapter provided an introduction to data wrangling techniques using Python, covering fundamental concepts and practical applications in data manipulation.</li>
                <li class="time">Time Spent: Approximately 4 hours.</li>
            </ul>
        </li>
        <li>
            <span class="book-title">Huxley et al. (2020) Data Cleaning. Sage Foundation.</span>
            <ul>
                <li>This article provided insights into various data cleaning methodologies, focusing on real-world applications and the importance of clean data in big data analytics.</li>
                <li class="time">Time Spent: Approximately 1 hours.</li>
            </ul>
        </li>
    </ul>
</div>

<div class="section">
    <div class="section-title">Additional Reading:</div>
    <ul>
        <li>
            <span class="book-title">Articles and papers related to the Internet of Things (IoT) and big data management strategies</span>
            <ul>
                <li>Reviewed to enhance understanding for the collaborative discussion.</li>
                <li class="time">Time Spent: Approximately 3 hours.</li>
            </ul>
        </li>
    </ul>
</div>

  <li>
    <span class="section-title">Practical Exercises:</span>
    <ul>
        <li>Enabled hands-on experience with various data formats (CSV, JSON, XML) and parsing techniques for human-readable formats (Excel, PDF).</li>
        <li>Highlighted the practical challenges and solutions in data wrangling and cleaning, directly relating to the methodologies and tools discussed in the lectures.</li>
    </ul>
</li>

         
      <h1>Collaborative Discussion 1 (WEEK 1) - The Data Collection Process</h1>
      <h2>Discussion Topic</h2>
      <p>Critically evaluate the rationale behind the Internet of Things (IOT), in the context of the article by Huxley et al (2020), highlighting the opportunities, limitations, risks and challenges associated with such a large-scale process of data collection.</p>

<p>In our discussion forum, four peers actively engaged in this topic. I discussed the intricacies of IoT with Panagiotis Mourtas and Aneta Worku, whose insights significantly enriched the discussion. My initial post focused on the dual aspects of opportunities and challenges associated with IoT, referencing key points from Huxley et al. (2020) and other academic literature.</p>

<p>Our discussions were detailed and comprehensive, covering various perspectives and reinforcing the importance of a balanced view of IoT. We collectively acknowledged the transformative potential of IoT while also recognizing the critical need for addressing its inherent challenges and risks.</p>

<p>More details about the initial posts and peer responses can be reached in the following links:</p>

      
      <a href="assets/pdf/bigdata-initial-post-1.pdf" target="_blank" class="btn btn-primary btn-custom">Initial Post</a>
      <a href="assets/pdf/bigdata-peer-responses-1.pdf" target="_blank" class="btn btn-primary">Peer Responses</a>
    </div>
    
        <div class="unit" id="unit2">
        <h2>Unit 2</h2>

         <h3>Introduction to Data Types and Formats<h3>
         <h4>Learning Outcomes</h4>
           
         <ul>
         <li>Differentiate among data formats and representations.<li>
         <li>Apply data formats and types in a variety of scenarios.<li>
         <li>Implement Python routines and applications using APIs.<li>
         <ul>

           </ul>
      <h3>Collaborative Discussion 1 (WEEK 2) - The Data Collection Process</h3>
      <h4>Discussion Topic</h4>
           
      <p>Critically evaluate the rationale behind the Internet of Things (IOT), in the context of the article by Huxley et al (2020), highlighting the opportunities, limitations, risks and challenges associated with such a large-scale process of data collection.</p>

      <h4>Learning Outcomes</h4>
           
        <ul>
        <li>Identify and manage challenges, security issues and risks, limitations, and opportunities in data wrangling.</li>
        <li>Critically analyse data wrangling problems and determine appropriate methodologies, tools, and techniques (involving preparing, cleaning, exploring, creating, optimising and evaluating big data) to solve them.</li>
        </ul>
      </ul>
      <a href="assets/pdf/bigdata-initial-post-1.pdf" target="_blank" class="btn btn-primary btn-custom">Initial Post</a>
      <a href="assets/pdf/bigdata-peer-responses-1.pdf" target="_blank" class="btn btn-primary">Peer Responses</a>
      </div>
    
             
    <div class="unit" id="unit3">
      
      <h2>Unit 3</h2>
       <h3>Data Collection and Storage<h3>
      <h4>Learning OUTCOMES</h4>
         
      <ul>
      <li>Understand data integrity and relevance to businesses.<li>
      <li>Apply data collection methods in a problem scenario.<li>
      <li>Conduct fact finding and fact checking.<li>
      <li>Understand the applicability of web services.<li>
      <ul>
        
      <h3>Web Scraping - ACTIVITY </h3>
      <h4>Learning OUTCOMES</h4>

      <ul>
      <li>Identify and manage challenges, security issues and risks, limitations, and opportunities in data wrangling.<li>
      <li>Critically analyse data wrangling problems and determine appropriate methodologies, tools, and techniques (involving preparing, cleaning, exploring, creating, optimising and evaluating big data) to solve them.<li>
      <li>Systematically develop and implement the skills required to be effective member of a development team in a virtual professional environment, adopting real life perspectives on team roles and organisation.<li>
      <ul>

      </ul>  
      <a href="assets/code/bigdata-webscraping-1.jpg" target="_blank" class="btn btn-primary btn-custom">Python code for Web Scraping </a>
      <a href="assets/pdf/web-scraping-report.pdf" target="_blank" class="btn btn-primary">Report: Web Scraping</a>
      <a href="assets/pdf/bigdata-summary-post-1.pdf" target="_blank" class="btn btn-primary">Summary Post</a>
      
    
    </div>
        
    <div class="unit" id="unit4">
      <h2>Unit 4</h2>
      <h3> Data Cleaning and Transformation</h3>

      <h4>Learning Outcomes</h4>
      
        <ul>
        <li>Gain an understanding and perform the basics and factors of data cleaning.</li>
        <li>Evaluate the critical outcomes for the data design and automation.</li>
        <li>Compile and document Python scripts.</li>
        <li>Compile data sets and convert data into different formats.</li>
        <ul>
          
        <h3>Data Management Pipeline Test.</h3>
      <h4>FEEDBACK</h4>
      <p>100 %</p>

      </ul>

      <a href="assets/pdf/bigdata-pipeline-test-1.pdf" target="_blank" class="btn btn-primary btn-custom">Test</a>
        <h3>UNIT EXERCISES</h3>

        <h4>Exercise 1</h4>
        <p>Follow the instructions on page 150-151 of the Data Wrangling with Python textbook to manually produce data files mn.csv and mn_headers.csv. 
        Perhaps the simplest approach to saving the cleaned data is to export it to a simple file, and the listed code saved to a new CSV file.</p>
        <a href="assets/code/big-data-data-cleaning-1.jpg" target="_blank" class="btn btn-primary btn-custom">Python code for Ex. 1</a>
        <a href="assets/pdf/Report%20on%20Data%20Cleaning%20and%20Processing%20Task.pdf" target="_blank" class="btn btn-primary btn-custom">Report: Data Cleaning</a>
        
        <h4>Exercise 2</h4>
        <p>The textbook continues to apply the rules for writing good code and produces a complete script with documentation. 
          Study the complete process listed on pages 199-209 of the Data Wrangling with Python textbook.</p>
        <a href="assets/code/big-data-data-cleaning-2.jpg" target="_blank" class="btn btn-primary btn-custom">Python code for Ex. 2</a>
        <a href="assets/pdf/Report%20on%20Data%20Cleaning%20and%20Processing%20Task%20-%20Documenting%20the%20Example.pdf" target="_blank" class="btn btn-primary btn-custom">Report: Documenting the Example</a>

    </div>
    <div class="unit" id="unit5">
      <h2>Unit 5</h2>

       <h3> Data Cleaning and Automating Data Collections</h3>

      <h4>Learning Outcomes</h4>
      
        <ul>
        <li>Examine data cleaning with the use of Python examples.</li>
           <li>Create data files and convert data sets to CSV format.</li>
 <li>Scrape appropriate web pages.</li>
 <li>Evaluate how Python scripts (codes) can be created for automating the cleaning process.</li>
 <li>Evaluate how automation uses machine learning strategies.</li>
 <li>Understand the use of database representation and architecture.</li>
       
        <ul>
          
        
    
    
    </div>
    <div class="unit" id="unit6">
      <h2>Unit 6</h2>
       <h3> Database Design and Normalisation</h3>

      <h4>Learning Outcomes</h4>
      
        <ul>
        <li>Evaluate how the cleaning methods help with the storage of useable datasets.</li>
        <li>Understand how a database is created and how it is linked with the use of key fields.</li>
        <li>Analyse anomalies and how they can affect the integrity of the database.</li>
        <li>Look at normalisation and the reasoning behind the use of different normal forms.</li>
        <ul>
          
        <h3>Development Team Project: Project Report</h3>
      <h4>Learning Outcomes</h4>
      
        <ul>
        <li>Critically analyse data wrangling problems and determine appropriate methodologies, tools, and techniques (involving preparing, cleaning, exploring, creating, optimising and evaluating big data) to solve them.
</li>
        <li>Systematically develop and implement the skills required to be effective member of a development team in a virtual professional environment, adopting real life perspectives on team roles and organisation.</li>
            <ul>

      </ul>

      <a href="assets/pdf/team-project-report.pdf" target="_blank" class="btn btn-primary btn-custom">Assessment</a>
    </div>
    <div class="unit" id="unit7">
      <h2>Unit 7</h2>
 <h3> Constructing Normalised Tables and Database Build</h3>

      <h4>Learning Outcomes</h4>
      
        <ul>
        <li>Examine data attributes, associations, operations and relationships.</li>
        <li>Normalise a set of data and Identify constraints associated with the application of the data attributes.</li>
        <li>Construct a relational database model based on normalised data.</li>
        <li>Test the database to check for any errors or anomalies.</li>
        <ul>
          
      <h3>Tasks</h3>
      <h4>1. Normalisation Task</h4>
      <p>Below you will see a table with data in un-normalised form. You should normalise this data to 3rd Normal Form (3NF), showing each step of the process i.e., demonstrating 1NF, 2NF and 3NF. Use the table below</p>
      <p>     </p>
          <h4>Learning Outcomes</h4>
      
        <ul>
        <li>Critically analyse data wrangling problems and determine appropriate methodologies, tools, and techniques (involving preparing, cleaning, exploring, creating, optimising and evaluating big data) to solve them.</li>
        <li>Design, develop and evaluate solutions for processing datasets and solving complex problems in various environments using relevant programming paradigms.</li>
        <li>Systematically develop and implement the skills required to be effective member of a development team in a virtual professional environment, adopting real life perspectives on team roles and organisation.</li>
        <ul>

      </ul>

           <a href="assets/excel/DBD_PCOM7E_Table.xlsx" target="_blank" class="btn btn-primary btn-custom">Table</a>
           <a href="assets/code/Normalisation-task-python.jpg" target="_blank" class="btn btn-primary btn-custom">Python code</a>
           <a href="assets/pdf/data-normalization.pdf" target="_blank" class="btn btn-primary btn-custom">Report: Data Normalization</a>
      <p>     </p>
      <p>     </p>

      <h4>2. Data Build Task</h4>
      <p>Once you have completed the Normalisation Task (also in this unit), you should then build a relational database system, with linked tables, demonstrating your knowledge of primary and secondary keys. Test your database to ensure referential integrity.</p>
      <h4>Learning Outcomes</h4>
      
        <ul>
        <li>Critically analyse data wrangling problems and determine appropriate methodologies, tools, and techniques (involving preparing, cleaning, exploring, creating, optimising and evaluating big data) to solve them</li>
        <li>Design, develop and evaluate solutions for processing datasets and solving complex problems in various environments using relevant programming paradigms.</li>
        <li>Systematically develop and implement the skills required to be effective member of a development team in a virtual professional environment, adopting real life perspectives on team roles and organisation.</li>
        <ul>

      </ul>

           <a href="assets/code/data-build-task-python.jpg" target="_blank" class="btn btn-primary btn-custom">Python code</a>
           <a href="assets/pdf/Report-on Data-Build-Task.pdf" target="_blank" class="btn btn-primary btn-custom">Report: Data Build Task</a>

           <p>     </p>
      <p>     </p>

      <h4>2. SQL Activity</h4>
     
    
           <a href="assets/pdf/sql-quiz.pdf" target="_blank" class="btn btn-primary btn-custom">SQL QUIZ & Results</a>

          
    </div>
    <div class="unit" id="unit8">
      <h2>Unit 8</h2>
      <h3> Compliance and Regulatory Framework for Managing Data</h3>

      <h4>Learning Outcomes</h4>
      
        <ul>
        <li>Analyse compliance obligations for data stakeholders.</li>
        <li>Examine rights accorded to individuals with respect to data usage.</li>
        <li>Understand applicable standards.</li>
        <li>Examine existing regulatory frameworks.</li>
        <li>Evaluate activities that require regulation.</li>
        <li>Review organisations and industry affected by regulation.</li>

        <ul>
          
        <h3>Collaborative Discussion 2 (WEEK 1)- Comparing Compliance Laws</h3>
      <h4>Discussion Topic</h4>
      <p>Compare the rules of the GDPR - in particular, with relation to the securing of personal data rule, with either similar compliance laws within your country of residence, or with the ICO in the UK.

The ICO refers to this rule as 'Security' and you should discuss your findings in relation to the standards set out and the exemptions that exist:</p>
          <ul>
          <li>'The securing personal data principle of the GDPR: Personal data shall be processed in a manner that ensures appropriate security of the personal data...' (ICO.org.uk).</li>
          <ul>
      <h4>Learning Outcomes</h4>
      
        <ul>
        <li>Identify and manage challenges, security issues and risks, limitations, and opportunities in data wrangling.</li>
        <ul>
          
      </ul>

      <a href="assets/pdf/big-data-initial-post-2.pdf" target="_blank" class="btn btn-primary btn-custom">Initial Post</a>
      <a href="assets/pdf/big-data-peer-responses-2.pdf" target="_blank" class="btn btn-primary btn-custom">Peer Responses</a>


 <h3>DreamHome Property Management Case Study</h3>
      <p>An overview of an example relational database, the DreamHome Property Management Case Study, is used to illustrate how to establish a database project. The case study illustrates how fact-finding techniques can be used and the documentation produced in the early stages of the database system development lifecycle, namely the database planning, system definition, and requirements collection and analysis stages.


      Consider the following requirements:

</p>
          <ul>
          <li>Study Chapter 10 to understand the overall concepts of a business information system, and the database development lifecycle (see figure 10.1). Consider the importance of database design and how the process can be decomposed into three phases: conceptual, logical, and physical database design. Note how the design of the application (the functional approach) affects database design (the data approach).</li>
          <li>A database project involves stakeholders from within an organisation as well as external stakeholders, and some may be technical while others are business oriented. A business value must be realised from an investment in the information system. Hence all stakeholders – particularly senior management – must be aware and convinced of the requirements and outcomes of the project. Database development must use fact-finding techniques to capture requirements and details from relevant stakeholders. Study chapter 11 to understand the most commonly used fact-finding techniques and identify the advantages and disadvantages of each (see sections 11.1-3).</li>
          <li>Details of the example DreamHome database are included in Appendix A. DreamHome is a fictitious property management company with branch offices in cities throughout the United Kingdom, each with allocated members of staff and a manager. Note the data and transactions requirement provided from a branch user view and from a staff user view.</li>
          <li>A worked example on using fact-finding techniques for the design of the DreamHome database is explained in section 11.4. Note the overview of the current system, and how the planning phase has contributions from the developer, director, manager, supervisor, and assistant. The system definition is then followed by requirement capturing involving the same stakeholders as well as the client. Note resulting documentation from these various stages.</li>


          <ul>
      <h4>Learning Outcomes</h4>
      
        <ul>
        <li>Identify and manage challenges, security issues and risks, limitations, and opportunities in data wrangling.</li>
          
        <li>Critically analyse data wrangling problems and determine appropriate methodologies, tools, and techniques (involving preparing, cleaning, exploring, creating, optimising and evaluating big data) to solve them.</li>
        <ul>
          
      </ul>

      <a href="assets/pdf/big-data-dreamHome.pdf" target="_blank" class="btn btn-primary btn-custom">DreamHome Case</a>

          
    </div>

        
          
    <div class="unit" id="unit9">
      <h2>Unit 9</h2>
      <h3> Database Management Systems (DBMS) and Models</h3>

      <h4>Learning Outcomes</h4>
      
        <ul>
        <li>Evaluate the design concepts and theories underpinning databases.</li>
        <li>Analyse strengths, limitations and application environments of DBMS.</li>
        <li>Examine the relevance of database designs to different programming paradigms.</li>
 
        <ul>
          
        <h3>Collaborative Discussion 2 (WEEK 2) - Comparing Compliance Laws</h3>
      <h4>Discussion Topic</h4>
      <p>Compare the rules of the GDPR - in particular, with relation to the securing of personal data rule, with either similar compliance laws within your country of residence, or with the ICO in the UK.

The ICO refers to this rule as 'Security' and you should discuss your findings in relation to the standards set out and the exemptions that exist:</p>
          <ul>
          <li>'The securing personal data principle of the GDPR: Personal data shall be processed in a manner that ensures appropriate security of the personal data...' (ICO.org.uk).</li>
          <ul>
      <h4>Learning Outcomes</h4>
      
        <ul>
        <li>Identify and manage challenges, security issues and risks, limitations, and opportunities in data wrangling.</li>
        <ul>
          
      </ul>

      <a href="assets/pdf/big-data-initial-post-2.pdf" target="_blank" class="btn btn-primary btn-custom">Initial Post</a>
      <a href="assets/pdf/big-data-peer-responses-2.pdf" target="_blank" class="btn btn-primary btn-custom">Peer Responses</a>


           <h3>Building a DBMS</h3>
      <p>Most Python codes and datasets are provided in files included in the Kazil textbook’s repository (see Unit 2 and 4 Reading). The main aim here is therefore not learning the Python programming language, but rather learning how Python may be used in data analysis.

Complete an example with storing data in a relational database. The example uses SQLite and includes the following parts:</p>
          <ul>
          <li>Installing SQLite and setting a relational database with Python: See the section Setting Up Your Local Database with Python on pages 145-146 of the Kazil textbook. You are also able to use the SQL workspace in Codio.</li>
          <li>Saving the cleaned UNICEF dataset into the SQLite database: See pages 193-194 and refer to Unit 4 if necessary.</li>

          <ul>
      <h4>Learning Outcomes</h4>
      
        <ul>
        <li>Critically analyse data wrangling problems and determine appropriate methodologies, tools, and techniques (involving preparing, cleaning, exploring, creating, optimising and evaluating big data) to solve them.</li>
          
        <li>Design, develop and evaluate solutions for processing datasets and solving complex problems in various environments using relevant programming paradigms.</li>
        <ul>
          
      </ul>

      <a href="assets/code/dreamhome.sql" target="_blank" class="btn btn-primary btn-custom">DreamHome SQL</a>
    </div>
    <div class="unit" id="unit10">
      <h2>Unit 10</h2>

      
    <h3> More on APIs (Application Programming Interfaces) for Data Parsing</h3>

      <h4>Learning Outcomes</h4>
      
        <ul>
        <li>Evaluate APIs and its use in data parsing and inter process communication.</li>
        <li>Examine the security requirements for ensuring the resilience of the functionality of APIs.</li>
        <li>Examine the challenges and issues associated with the implementation of APIs.</li>
 
        <ul>
          
        <h3>Collaborative Discussion 2 (WEEK 3) - Comparing Compliance Laws</h3>
      <h4>Discussion Topic</h4>
      <p>Compare the rules of the GDPR - in particular, with relation to the securing of personal data rule, with either similar compliance laws within your country of residence, or with the ICO in the UK.

The ICO refers to this rule as 'Security' and you should discuss your findings in relation to the standards set out and the exemptions that exist:</p>
          <ul>
          <li>'The securing personal data principle of the GDPR: Personal data shall be processed in a manner that ensures appropriate security of the personal data...' (ICO.org.uk).</li>
          <ul>
      <h4>Learning Outcomes</h4>
      
        <ul>
        <li>Identify and manage challenges, security issues and risks, limitations, and opportunities in data wrangling.</li>
        <ul>
          
      </ul>

      <a href="assets/pdf/big-data-summary-post-2.pdf" target="_blank" class="btn btn-primary btn-custom">Summary Post</a>

           <h3>API Security Requirements</h3>
      <p>As a team, evaluate the security requirements of an API of your choice and write a brief security requirements specification which mitigates against any risks associated with the API for enabling data sharing, scraping and connectivity between a program code written in Python and any of the following file formats/management systems (XML, JSON and SQL).

</p>
          
      <h4>Learning Outcomes</h4>
      
        <ul>
        <li>Identify and manage challenges, security issues and risks, limitations, and opportunities in data wrangling.</li>
          
        <li>Critically analyse data wrangling problems and determine appropriate methodologies, tools, and techniques (involving preparing, cleaning, exploring, creating, optimising and evaluating big data) to solve them.</li>
        <ul>
          
      </ul>

      <a href="assets/pdf/big-data-api.pdf" target="_blank" class="btn btn-primary btn-custom">Report </a>
    
    
        
          </div>
    <div class="unit" id="unit11">
      <h2>Unit 11</h2>

      
    <h3> DBMS Transaction and Recovery</h3>

      <h4>Learning Outcomes</h4>
      
        <ul>
        <li>Introduce transaction processing.</li>
        <li>Identify the ACID transaction state and their effects on the transaction cycle.</li>
        <li>Examine scheduled transactions, system failures and checkpoints.</li>
 
        <ul>
          
        

           <h3>Back Up Procedure</h3>
      <p>In 100 - 150 words, critically evaluate the disaster recovery system called the “Grandfather-Father-Son" GFS backup procedure. Using the sites listed in this week’s reading list as an introduction to the topic, highlight how the strategy makes the back-up of large databases less resource heavy and argue whether this strategy is effective when compared to other methods of backing up data.

</p>
          
      <h4>Learning Outcomes</h4>
      
        <ul>
        <li>Identify and manage challenges, security issues and risks, limitations, and opportunities in data wrangling.</li>
          
        <li>Critically analyse data wrangling problems and determine appropriate methodologies, tools, and techniques (involving preparing, cleaning, exploring, creating, optimising and evaluating big data) to solve them.</li>
        <li>Design, develop and evaluate solutions for processing datasets and solving complex problems in various environments using relevant programming paradigms.</li>

        <ul>
          
      </ul>

      <a href="assets/pdf/big-data-backup.pdf" target="_blank" class="btn btn-primary btn-custom">Report </a>
    
    
    
    
    </div>
    <div class="unit" id="unit12">
      <h2>Unit 12</h2>

      
         
    <h3> Future of Big Data Analytics</h3>

      <h4>Learning Outcomes</h4>
      
        <ul>
        <li>Explore the future of big data analytics.</li>
        <li>Examine machine learning and applications.</li>
        <li>Reflect on the applicability of these topics to an organisation.</li>
 
        <ul>
          
        

           <h3>Content Challenge</h3>
      <p>This module has extensively covered data wrangling processes. This last seminar will provide a discursive overview of the module to help with your final reflection and e-portfolio development. Review the content of this week's Lecturecast (Reflective Research Activities) and the questions below. You can carry out the review as a team or on your own:



</p>
          
      <h4>Learning Outcomes</h4>
      
        <ul>
        <li>Identify and manage challenges, security issues and risks, limitations, and opportunities in data wrangling.</li>
          
        <li>Critically analyse data wrangling problems and determine appropriate methodologies, tools, and techniques (involving preparing, cleaning, exploring, creating, optimising and evaluating big data) to solve them.</li>
        <li>Systematically develop and implement the skills required to be effective member of a development team in a virtual professional environment, adopting real life perspectives on team roles and organisation.</li>

        <ul>
          
      </ul>

      <a href="assets/pdf/big-data-challenge.pdf" target="_blank" class="btn btn-primary btn-custom">Questions & Answers </a>
    
    
    </div>
  </div>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.0/dist/js/bootstrap.bundle.min.js"
    integrity="sha384-p34f1UUtsS3wqzfto5wAAmdvj+osOnFyQFpp4Ua3gs/ZVWx6oOypYoCJhGGScy+8"
    crossorigin="anonymous"></script>
  <script src="https://kit.fontawesome.com/4ad03fe072.js" crossorigin="anonymous"></script>
</body>

</html>
